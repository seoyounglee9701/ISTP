{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmt 기본 모델 (scene encoder 포함)에 대한 궤적 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 디렉토리: /home/ngnadmin/dev/ngn_2024/MMT4/MMT/vis/tf\n",
      "MMT4 디렉토리(_path):/home/ngnadmin/dev/ngn_2024/MMT4/MMT\n"
     ]
    }
   ],
   "source": [
    "_path = os.getcwd()\n",
    "print(f\"현재 디렉토리: {_path}\")\n",
    "\n",
    "_path = _path.split(\"/\")[:-2]\n",
    "_path = \"/\".join(_path)\n",
    "print(f\"MMT4 디렉토리(_path):{_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-dark\")\n",
    "###### loader check ######\n",
    "from mmt.data.loader_sdd import data_loader\n",
    "###### model check #######\n",
    "from mmt.models2_eth.mmtf_noscene_v2_2 import TrajectoryGenerator\n",
    "# from mmt.models2_eth.mmtf_noscene_nostate import TrajectoryGenerator\n",
    "from mmt.utils import (\n",
    "    int_tuple,\n",
    "    relative_to_abs,\n",
    "    get_dset_path,\n",
    ")\n",
    "from mmt.losses import(\n",
    "    displacement_error,\n",
    "    final_displacement_error,\n",
    "    l2_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class CreateArg():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.num_samples = 20 # type=int\n",
    "\n",
    "        # Dataset options\n",
    "        self.dataset_name = 'sdd_dC'\n",
    "        self.delim = '\\t'\n",
    "        self.loader_num_workers = 0 # 4 -> 1\n",
    "        self.obs_len = 8\n",
    "        self.pred_len = 8                   ############################### pred_len check !!!\n",
    "        self.skip = 1\n",
    "        # Optimization\n",
    "        self.batch_size = 64                 ################################  batch_size check !!!\n",
    "        self.num_iterations = 1000 # \n",
    "        self.num_epochs = 50 #                      \n",
    "        # Model Options\n",
    "        self.embedding_dim = 64\n",
    "        self.num_lstm_layers = 1\n",
    "        self.num_tf_layers = 4\n",
    "        self.dropout = 0.0\n",
    "        self.batch_norm = 0 \n",
    "        self.mlp_dim = 1024\n",
    "        self.state_type = 2\n",
    "                                    \n",
    "        # Generator Options\n",
    "        self.encoder_h_dim_g = 64\n",
    "        self.decoder_h_dim_g = 128\n",
    "        self.noise_dim : Tuple[int] = (0, 0) # default=None # type=int_tuple\n",
    "        self.noise_type = 'gaussian'\n",
    "        self.noise_mix_type = 'ped'\n",
    "        self.clipping_threshold_g = 0 # type=float\n",
    "        self.g_learning_rate = 5e-4 # type=float \n",
    "        self.g_steps = 1\n",
    "\n",
    "        # Pooling Options\n",
    "        self.pooling_type = 'pool_net' \n",
    "        self.pool_every_timestep = 1 # type=bool_flag\n",
    "\n",
    "        # Pool Net Option\n",
    "        self.bottleneck_dim = 1024 # type=int\n",
    "\n",
    "        # Social Pooling Options\n",
    "        # self.neighborhood_size = 1024 # type=float\n",
    "        # self.grid_size = 8 # type=int\n",
    "\n",
    "        # Discriminator Options\n",
    "        self.d_type = 'local' # type=str\n",
    "        self.encoder_h_dim_d = 64 # type=int\n",
    "        self.d_learning_rate = 5e-4 # type=float\n",
    "        self.d_steps = 2 # type=int        \n",
    "        self.clipping_threshold_d = 0 # type=float  \n",
    "\n",
    "        # Loss Options\n",
    "        self.l2_loss_weight = 0 # type=float \n",
    "        self.best_k = 1 # type=int \n",
    "\n",
    "        # Output\n",
    "        # 궤적 이미지 출력 폴더\n",
    "        self.output_dir = os.getcwd()+ '/fig/noscene/state0/obs8/2'\n",
    "        self.print_every = 5 # type=int\n",
    "        self.checkpoint_every = 100 # type=int\n",
    "        # self.checkpoint_name = 'checkpoint_basic' \n",
    "        self.checkpoint_start_from = None\n",
    "        self.restore_from_checkpoint = 1 # type=int\n",
    "        self.num_samples_check = 5000 # type=int        \n",
    "\n",
    "        # Misc\n",
    "        self.use_gpu = 0 # type=int\n",
    "        self.timing = 0 # type=int\n",
    "        self.gpu_num = \"0\" # type=str   \n",
    "\n",
    "        # Log\n",
    "        # self.log_dir = \"./\"\n",
    "        self.restore_path = \"/home/ngnadmin/dev/ngn_2024/MMT4/MMT/scripts2_sdd/output/noscene_v2_2/state2/obs8/2/tf_2.2_2_with_model.pt\"\n",
    "        # self.restore_path = os.getcwd()[:-4]+ '/scripts/output/scene/state2/obs8/'+'scene_state_v2_with_model.pt'\n",
    "\n",
    "\n",
    "args = CreateArg() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restore_path: /home/ngnadmin/dev/ngn_2024/MMT4/MMT/scripts2_sdd/output/noscene_v2_2/state2/obs8/2/tf_2.2_2_with_model.pt\n",
      "output_dir: /home/ngnadmin/dev/ngn_2024/MMT4/MMT/vis/tf/fig/noscene/state0/obs8/2\n",
      "batch_size: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"restore_path: {args.restore_path}\")\n",
    "print(f\"output_dir: {args.output_dir}\")\n",
    "print(f\"batch_size: {args.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_helper(error, seq_start_end, model_output_traj, model_output_traj_best):\n",
    "    error = torch.stack(error, dim=1)\n",
    "    for (start, end) in seq_start_end:\n",
    "        start = start.item()\n",
    "        end = end.item()\n",
    "        _error = error[start:end]\n",
    "        _error = torch.sum(_error, dim=0)\n",
    "        min_index = _error.min(0)[1].item()\n",
    "        model_output_traj_best[:, start:end, :] = model_output_traj[min_index][\n",
    "            :, start:end, :\n",
    "        ]\n",
    "    return model_output_traj_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(checkpoint):\n",
    "    # n_units = (\n",
    "    #     [args.traj_lstm_hidden_size]\n",
    "    #     + [int(x) for x in args.hidden_units.strip().split(\",\")]\n",
    "    #     + [args.graph_lstm_hidden_size]\n",
    "    # )\n",
    "    # n_heads = [int(x) for x in args.heads.strip().split(\",\")]\n",
    "    generator = TrajectoryGenerator(\n",
    "        obs_len=args.obs_len,\n",
    "        pred_len=args.pred_len,\n",
    "        state_type = args.state_type, # \n",
    "        embedding_dim=args.embedding_dim,\n",
    "        encoder_h_dim=args.encoder_h_dim_g,\n",
    "        decoder_h_dim=args.decoder_h_dim_g,\n",
    "        mlp_dim=args.mlp_dim,\n",
    "        num_lstm_layers=args.num_lstm_layers,\n",
    "        num_tf_layers=args.num_tf_layers,\n",
    "        noise_dim=args.noise_dim,\n",
    "        noise_type=args.noise_type,\n",
    "        noise_mix_type=args.noise_mix_type,\n",
    "        pooling_type=args.pooling_type,\n",
    "        pool_every_timestep=args.pool_every_timestep,\n",
    "        dropout=args.dropout,\n",
    "        bottleneck_dim=args.bottleneck_dim,\n",
    "        # neighborhood_size=args.neighborhood_size,\n",
    "        # grid_size=args.grid_size,\n",
    "        batch_norm=args.batch_norm)\n",
    "    generator.load_state_dict(checkpoint[\"g_state\"])\n",
    "    generator.cuda()\n",
    "    generator.eval()\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ade_fde(pred_traj_gt, pred_traj_fake):\n",
    "    ade = displacement_error(pred_traj_fake, pred_traj_gt, mode=\"raw\")\n",
    "    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1], mode=\"raw\")\n",
    "    return ade, fde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(args, loader, generator):\n",
    "    ground_truth_input = []\n",
    "    all_model_output_traj = []\n",
    "    ground_truth_output = []\n",
    "    pic_cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = [tensor.cuda() for tensor in batch]\n",
    "            (obs_traj, obs_sel_state,    \n",
    "            pred_traj_gt, _, \n",
    "            obs_traj_rel, pred_traj_gt_rel, \n",
    "            _, loss_mask, seq_start_end\n",
    "            # ,  _\n",
    "            ) = batch\n",
    "            ade = []\n",
    "            ground_truth_input.append(obs_traj)\n",
    "            ground_truth_output.append(pred_traj_gt)\n",
    "            model_output_traj = []\n",
    "            model_output_traj_best = torch.ones_like(pred_traj_gt).cuda() # 동일한 shpae의 tensro를 1로 채워줌\n",
    "\n",
    "            for _ in range(args.num_samples):\n",
    "\n",
    "                pred_traj_fake_rel = generator(\n",
    "                    obs_traj, obs_traj_rel, seq_start_end,\n",
    "                    obs_sel_state\n",
    "                )\n",
    "\n",
    "                # pred_traj_fake_rel = pred_traj_fake_rel[-args.pred_len :] #\n",
    "\n",
    "                pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1]) #\n",
    "\n",
    "                model_output_traj.append(pred_traj_fake) # \n",
    "\n",
    "                ade_, fde_ = cal_ade_fde(pred_traj_gt, pred_traj_fake)\n",
    "                ade.append(ade_)\n",
    "            model_output_traj_best = evaluate_helper(\n",
    "                ade, seq_start_end, model_output_traj, model_output_traj_best\n",
    "            )\n",
    "            all_model_output_traj.append(model_output_traj_best)\n",
    "\n",
    "            for (start, end) in seq_start_end:\n",
    "                plt.figure(figsize=(7.88,10.8), dpi=100)\n",
    "                ground_truth_input_x_piccoor = (\n",
    "                    obs_traj[:, start:end, :].cpu().numpy()[:, :, 0].T\n",
    "                )\n",
    "                ground_truth_input_y_piccoor = (\n",
    "                    obs_traj[:, start:end, :].cpu().numpy()[:, :, 1].T\n",
    "                )\n",
    "                ground_truth_output_x_piccoor = (\n",
    "                    pred_traj_gt[:, start:end, :].cpu().numpy()[:, :, 0].T\n",
    "                )\n",
    "                ground_truth_output_y_piccoor = (\n",
    "                    pred_traj_gt[:, start:end, :].cpu().numpy()[:, :, 1].T\n",
    "                )\n",
    "                model_output_x_piccoor = (\n",
    "                    model_output_traj_best[:, start:end, :].cpu().numpy()[:, :, 0].T\n",
    "                )\n",
    "                model_output_y_piccoor = (\n",
    "                    model_output_traj_best[:, start:end, :].cpu().numpy()[:, :, 1].T\n",
    "                )\n",
    "                for i in range(ground_truth_output_x_piccoor.shape[0]):\n",
    "\n",
    "                    # observed_line = plt.plot(\n",
    "                    #     ground_truth_input_x_piccoor[i, :],\n",
    "                    #     ground_truth_input_y_piccoor[i, :],\n",
    "                    #     \"r-\",\n",
    "                    #     linewidth=4,\n",
    "                    #     label=\"Observed Trajectory\",\n",
    "                    # )[0]\n",
    "                    # observed_line.axes.annotate(\n",
    "                    #     \"\",\n",
    "                    #     xytext=(\n",
    "                    #         ground_truth_input_x_piccoor[i, -2],\n",
    "                    #         ground_truth_input_y_piccoor[i, -2],\n",
    "                    #     ),\n",
    "                    #     xy=(\n",
    "                    #         ground_truth_input_x_piccoor[i, -1],\n",
    "                    #         ground_truth_input_y_piccoor[i, -1],\n",
    "                    #     ),\n",
    "                    #     # arrowprops=dict(\n",
    "                    #     #     arrowstyle=\"->\", color=observed_line.get_color(), lw=1\n",
    "                    #     # ),\n",
    "                    #     size=20,\n",
    "                    # )\n",
    "                    # ground_line = plt.plot(\n",
    "                    #     np.append(\n",
    "                    #         ground_truth_input_x_piccoor[i, -1],\n",
    "                    #         ground_truth_output_x_piccoor[i, :],\n",
    "                    #     ),\n",
    "                    #     np.append(\n",
    "                    #         ground_truth_input_y_piccoor[i, -1],\n",
    "                    #         ground_truth_output_y_piccoor[i, :],\n",
    "                    #     ),\n",
    "                    #     \"b-\",\n",
    "                    #     linewidth=4,\n",
    "                    #     label=\"Ground Truth\",\n",
    "                    # )[0]\n",
    "                    predict_line = plt.plot(\n",
    "                        np.append(\n",
    "                            ground_truth_input_x_piccoor[i, -1],\n",
    "                            model_output_x_piccoor[i, :],\n",
    "                        ),\n",
    "                        np.append(\n",
    "                            ground_truth_input_y_piccoor[i, -1],\n",
    "                            model_output_y_piccoor[i, :],\n",
    "                        ),\n",
    "                        color=\"#FF00FF\", # 핑크 \"#ADFF2F\", # 연두 \"#ffff00\", # 노랑\n",
    "                        ls=\"--\",\n",
    "                        linewidth=4,\n",
    "                        label=\"Predicted Trajectory\",\n",
    "                    )[0]\n",
    "\n",
    "                plt.axis(\"on\")\n",
    "                \n",
    "                plt.savefig(\n",
    "                    args.output_dir+\"/pic_{}.png\".format(pic_cnt),\n",
    "                    transparent=True\n",
    "                )\n",
    "                plt.close()\n",
    "                pic_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    checkpoint = torch.load(args.restore_path) # .pt 파일을 불러올 경로\n",
    "    generator = get_generator(checkpoint)\n",
    "    # path = get_dset_path(args.dataset_name, args.dset_type)\n",
    "    dst_path = args.output_dir\n",
    "    if not os.path.exists(dst_path):\n",
    "        os.makedirs(dst_path)\n",
    "        print(f\"Directory {dst_path} created.\")\n",
    "    else:\n",
    "        print(f\"Directory {dst_path} already exists.\")\n",
    "    path = '/home/ngnadmin/dev/ngn_2024/MMT4/MMT/mmt/datasets/sdd_dC/test2'\n",
    "    _, loader = data_loader(args, path)\n",
    "    plot_trajectory(args, loader, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불러올 모델 체크포인트 파일 경로: /home/ngnadmin/dev/ngn_2024/MMT4/MMT/scripts2_sdd/output/noscene_v2_2/state2/obs8/2/tf_2.2_2_with_model.pt\n",
      "이미지가 저장될 위치: /home/ngnadmin/dev/ngn_2024/MMT4/MMT/vis/tf/fig/noscene/state0/obs8/2\n",
      "투명 배경 저장\n",
      "축on\n"
     ]
    }
   ],
   "source": [
    "# 주요 변수 확인\n",
    "print(f\"불러올 모델 체크포인트 파일 경로: {args.restore_path}\")\n",
    "print(f\"이미지가 저장될 위치: {args.output_dir}\")\n",
    "print(\"투명 배경 저장\")\n",
    "print(\"축on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_type:2번째 상태 인코더\n",
      "state_size:1\n",
      "input_dim:1152\n",
      "Directory /home/ngnadmin/dev/ngn_2024/MMT4/MMT/vis/tf/fig/noscene/state0/obs8/2 created.\n",
      "obs_len:8\n",
      "pred_len:8\n",
      "state_type:2\n",
      "seq_len: 16\n",
      "test2 / file_path:/home/ngnadmin/dev/ngn_2024/MMT4/MMT/mmt/datasets/sdd_dC/test2/sdd_test_v2.csv\n",
      "1 of total 1 \n",
      "len frames:452\n",
      "num_sequences:437\n",
      "e_count:0\n"
     ]
    }
   ],
   "source": [
    "seed = 2024\n",
    "deterministic = True\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "if deterministic:\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "\t\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmtp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
