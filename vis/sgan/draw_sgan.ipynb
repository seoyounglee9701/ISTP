{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgan 모델에 대한 궤적 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 디렉토리: /home/ngnadmin/dev/ngn_2024/MMT4/MMT/vis/sgan\n",
      "MMT3 디렉토리(_path):/home/ngnadmin/dev/ngn_2024/MMT4/MMT\n"
     ]
    }
   ],
   "source": [
    "_path = os.getcwd()\n",
    "print(f\"현재 디렉토리: {_path}\")\n",
    "\n",
    "_path = _path.split(\"/\")[:-2]\n",
    "_path = \"/\".join(_path)\n",
    "print(f\"MMT4 디렉토리(_path):{_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(_path) # MMT3 디렉토리를 path 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-dark\")\n",
    "###### loader check ######\n",
    "from mmt.data.loader import data_loader\n",
    "###### model check #######\n",
    "from mmt.models_eth.mmt_noscene import TrajectoryGenerator\n",
    "from mmt.utils import (\n",
    "    int_tuple,\n",
    "    relative_to_abs,\n",
    "    get_dset_path,\n",
    ")\n",
    "from mmt.losses import(\n",
    "    displacement_error,\n",
    "    final_displacement_error,\n",
    "    l2_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class CreateArg():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.num_samples = 20 # type=int\n",
    "\n",
    "        # Dataset options\n",
    "        self.dataset_name = 'sdd_dC'\n",
    "        self.delim = '\\t'\n",
    "        self.loader_num_workers = 0 # 4 -> 1\n",
    "        self.obs_len = 8\n",
    "        self.pred_len = 8                   ############################### pred_len check !!!\n",
    "        self.skip = 1\n",
    "        # Optimization\n",
    "        self.batch_size = 8                 ################################  batch_size check !!! (scene encoder 있는 경우 1)\n",
    "        self.num_iterations = 1000 # \n",
    "        self.num_epochs = 50 #                      \n",
    "        # Model Options\n",
    "        self.embedding_dim = 64\n",
    "        self.num_layers = 1\n",
    "        self.dropout = 0.0\n",
    "        self.batch_norm = 0 \n",
    "        self.mlp_dim = 1024\n",
    "        self.state_type = 2\n",
    "                                    \n",
    "        # Generator Options\n",
    "        self.encoder_h_dim_g = 64\n",
    "        self.decoder_h_dim_g = 128\n",
    "        self.noise_dim : Tuple[int] = (0, 0) # default=None # type=int_tuple\n",
    "        self.noise_type = 'gaussian'\n",
    "        self.noise_mix_type = 'ped'\n",
    "        self.clipping_threshold_g = 0 # type=float\n",
    "        self.g_learning_rate = 5e-4 # type=float \n",
    "        self.g_steps = 1\n",
    "\n",
    "        # Pooling Options\n",
    "        self.pooling_type = 'pool_net' \n",
    "        self.pool_every_timestep = 1 # type=bool_flag\n",
    "\n",
    "        # Pool Net Option\n",
    "        self.bottleneck_dim = 1024 # type=int\n",
    "\n",
    "        # Discriminator Options\n",
    "        self.d_type = 'local' # type=str\n",
    "        self.encoder_h_dim_d = 64 # type=int\n",
    "        self.d_learning_rate = 5e-4 # type=float\n",
    "        self.d_steps = 2 # type=int        \n",
    "        self.clipping_threshold_d = 0 # type=float  \n",
    "\n",
    "        # Loss Options\n",
    "        self.l2_loss_weight = 0 # type=float \n",
    "        self.best_k = 1 # type=int \n",
    "\n",
    "        # Output\n",
    "        # 궤적 이미지 출력 폴더\n",
    "        self.output_dir = os.getcwd()+ '/fig/obs8/1'\n",
    "        self.print_every = 5 # type=int\n",
    "        self.checkpoint_every = 100 # type=int\n",
    "        self.checkpoint_start_from = None\n",
    "        self.restore_from_checkpoint = 1 # type=int\n",
    "        self.num_samples_check = 5000 # type=int        \n",
    "\n",
    "        # Misc\n",
    "        self.use_gpu = 1 # type=int\n",
    "        self.timing = 0 # type=int\n",
    "        self.gpu_num = \"0\" # type=str   \n",
    "\n",
    "        # 시각화 할 모델 경로 (체크포인트)\n",
    "        self.restore_path = \"/home/ngnadmin/dev/ngn_2024/MMT4/MMT/scripts_sdd/output/noscene/state0/obs8/1/lstm_0_with_model.pt\"\n",
    "\n",
    "\n",
    "args = CreateArg() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restore_model_path: /home/ngnadmin/dev/ngn_2024/MMT4/MMT/scripts_sdd/output/noscene/state0/obs8/1/lstm_0_with_model.pt\n",
      "img output_dir: /home/ngnadmin/dev/ngn_2024/MMT4/MMT/vis/sgan/fig/obs8/1\n",
      "batch_size: 8\n"
     ]
    }
   ],
   "source": [
    "# 주요 변수 확인\n",
    "print(f\"restore_model_path: {args.restore_path}\")\n",
    "print(f\"img output_dir: {args.output_dir}\")\n",
    "print(f\"batch_size: {args.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오류를 기반으로 모델 여러 출력 중 가장 좋은 경로를 선택\n",
    "def evaluate_helper(error, seq_start_end, model_output_traj, model_output_traj_best):\n",
    "    error = torch.stack(error, dim=1) # 모델 출력 에러를 나타내는 텐서들 리스트 스택\n",
    "    for (start, end) in seq_start_end:\n",
    "        start = start.item()\n",
    "        end = end.item()\n",
    "        _error = error[start:end] # error 텐서에서 해당 시퀀스의 시퀀스 에러 부분을 추출\n",
    "        _error = torch.sum(_error, dim=0) # 각 경로에 대한 총 에러 계산산\n",
    "        min_index = _error.min(0)[1].item() # 총 에러가 가장 작은 경로 인덱스 구하기기\n",
    "        model_output_traj_best[:, start:end, :] = model_output_traj[min_index][ # 가장 작은 에러를 가진 경로를 해당 시퀀스에 복사\n",
    "            :, start:end, :\n",
    "        ]\n",
    "    return model_output_traj_best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(checkpoint):\n",
    "    # n_units = (\n",
    "    #     [args.traj_lstm_hidden_size]\n",
    "    #     + [int(x) for x in args.hidden_units.strip().split(\",\")]\n",
    "    #     + [args.graph_lstm_hidden_size]\n",
    "    # )\n",
    "    # n_heads = [int(x) for x in args.heads.strip().split(\",\")]\n",
    "    generator = TrajectoryGenerator(\n",
    "        obs_len=args.obs_len,\n",
    "        pred_len=args.pred_len, \n",
    "        state_type=args.state_type,\n",
    "        embedding_dim=args.embedding_dim,\n",
    "        encoder_h_dim=args.encoder_h_dim_g,\n",
    "        decoder_h_dim=args.decoder_h_dim_g,\n",
    "        mlp_dim=args.mlp_dim,\n",
    "        num_layers=args.num_layers,\n",
    "        noise_dim=args.noise_dim,\n",
    "        noise_type=args.noise_type,\n",
    "        noise_mix_type=args.noise_mix_type,\n",
    "        pooling_type=args.pooling_type,\n",
    "        pool_every_timestep=args.pool_every_timestep,\n",
    "        dropout=args.dropout,\n",
    "        bottleneck_dim=args.bottleneck_dim,\n",
    "        # neighborhood_size=args.neighborhood_size,\n",
    "        # grid_size=args.grid_size,\n",
    "        batch_norm=args.batch_norm\n",
    "    )\n",
    "    generator.load_state_dict(checkpoint[\"g_state\"])\n",
    "    generator.cuda()\n",
    "    generator.eval()\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ade_fde(pred_traj_gt, pred_traj_fake):\n",
    "    ade = displacement_error(pred_traj_fake, pred_traj_gt, mode=\"raw\")\n",
    "    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1], mode=\"raw\")\n",
    "    return ade, fde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(args, loader, generator):\n",
    "    ground_truth_input = [] # 관찰된 궤적\n",
    "    all_model_output_traj = [] # 모델의 모든 예측 궤적\n",
    "    ground_truth_output = [] # 실제 궤적을 저장하기 위한 리스트\n",
    "    pic_cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = [tensor.cuda() for tensor in batch]\n",
    "            (obs_traj, _, _,     \n",
    "            pred_traj_gt, _, _,\n",
    "            obs_traj_rel, pred_traj_gt_rel, \n",
    "            _, loss_mask, seq_start_end,  _\n",
    "            ) = batch\n",
    "            ade = []\n",
    "            ground_truth_input.append(obs_traj)\n",
    "            ground_truth_output.append(pred_traj_gt)\n",
    "            model_output_traj = []\n",
    "            model_output_traj_best = torch.ones_like(pred_traj_gt).cuda() # 동일한 shpae의 tensor를 1로 채워줌\n",
    "\n",
    "            for _ in range(args.num_samples):\n",
    "\n",
    "                pred_traj_fake_rel = generator(\n",
    "                                    obs_traj, obs_traj_rel, seq_start_end,\n",
    "                                  )\n",
    "\n",
    "                pred_traj_fake_rel = pred_traj_fake_rel[-args.pred_len :] # 시퀀스 마지막 pred_len 길이 만큼 (예측한 부분)\n",
    "\n",
    "                pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1]) #\n",
    "\n",
    "                model_output_traj.append(pred_traj_fake) # \n",
    "\n",
    "                ade_, fde_ = cal_ade_fde(pred_traj_gt, pred_traj_fake)\n",
    "                ade.append(ade_)\n",
    "            model_output_traj_best = evaluate_helper(\n",
    "                ade, seq_start_end, model_output_traj, model_output_traj_best   # 가장 작은 ADE 가진 예측 궤적을 선택하고 최적 궤적 텐서에 저장함\n",
    "            )\n",
    "            all_model_output_traj.append(model_output_traj_best)\n",
    "\n",
    "            for (start, end) in seq_start_end:\n",
    "                plt.figure(figsize=(20,15), dpi=100)\n",
    "                ground_truth_input_x_piccoor = (    # 관찰된 궤적 x\n",
    "                    obs_traj[:, start:end, :].cpu().numpy()[:, :, 0].T\n",
    "                )\n",
    "                ground_truth_input_y_piccoor = (  # 관찰된 궤적 y\n",
    "                    obs_traj[:, start:end, :].cpu().numpy()[:, :, 1].T\n",
    "                )\n",
    "                ground_truth_output_x_piccoor = (   # 실제 궤적 x\n",
    "                    pred_traj_gt[:, start:end, :].cpu().numpy()[:, :, 0].T\n",
    "                )\n",
    "                ground_truth_output_y_piccoor = (   # 실제 궤적 y\n",
    "                    pred_traj_gt[:, start:end, :].cpu().numpy()[:, :, 1].T\n",
    "                )\n",
    "                model_output_x_piccoor = (          # 모델이 예측한 궤적 x\n",
    "                    model_output_traj_best[:, start:end, :].cpu().numpy()[:, :, 0].T\n",
    "                )\n",
    "                model_output_y_piccoor = (           # 모델이 예측한 궤적 y\n",
    "                    model_output_traj_best[:, start:end, :].cpu().numpy()[:, :, 1].T\n",
    "                )\n",
    "                # print(\"model_output_traj_best shape:\", model_output_traj_best.shape) # (8, 71, 2)\n",
    "                # print(\"model_output_traj_best values:\", model_output_traj_best)\n",
    "\n",
    "                # print(\"model_output_traj_best shape:\", model_output_traj_best.shape) # (8, 71, 2)\n",
    "                # print(\"model_output_traj_best values:\", model_output_traj_best)\n",
    "\n",
    "                # print(\"model_output_traj_best shape:\", model_output_traj_best.shape) # (8, 71, 2)\n",
    "                # print(\"model_output_traj_best values:\", model_output_traj_best)\n",
    "                \n",
    "                # sys.exit()\n",
    "\n",
    "                for i in range(ground_truth_output_x_piccoor.shape[0]): # 샘플 수\n",
    "\n",
    "                    observed_line = plt.plot(                   # plot에 선을 그리는 함수: 관찰된 궤적을 플롯으로 그리기\n",
    "                        ground_truth_input_x_piccoor[i, :], # i번째 샘플의 모든 관찰된 x 좌표\n",
    "                        ground_truth_input_y_piccoor[i, :],\n",
    "                        color=\"#FF5733\", # 다홍색 // # \"r-\",   # 빨간 선\n",
    "                        linewidth=4,\n",
    "                        label=\"Observed Trajectory\", # 범례에 이 선을 라벨링\n",
    "                        alpha=0.7,\n",
    "                    )[0]                                # plot 함수는 리스트를 반환, 첫 요소가 실제 그린 선을 나타내는 Line2D 객체\n",
    "                    observed_line.axes.annotate(    # observed_line 객체의 축(axis)에 주석을 추가하는 함수, annotate 함수는 텍스트 주석과 함께 화살표 추가\n",
    "                        \"\", # 주석으로 표시할 텍스트, 텍스트는 표시 않고, 화살표만 그리기\n",
    "                        xytext=( # 화살표 시작점\n",
    "                            ground_truth_input_x_piccoor[i, -2], # i번째 샘플의 두 번째 마지막 x 좌표\n",
    "                            ground_truth_input_y_piccoor[i, -2],\n",
    "                        ),\n",
    "                        xy=( # 화살표 끝점점\n",
    "                            ground_truth_input_x_piccoor[i, -1], # i번째 샘플의 마지막 x 좌표\n",
    "                            ground_truth_input_y_piccoor[i, -1],\n",
    "                        ),\n",
    "                        arrowprops=dict(\n",
    "                            arrowstyle=\"->\", color=observed_line.get_color(), lw=1 # 화살표 스타일 지정: 머리가 점을 향하도록, color: 화살표 색상을 observed_line과 동일하게, 화살표 두께=1\n",
    "                        ),\n",
    "                        size=20, # 주석 텍스트 크기\n",
    "                    )\n",
    "\n",
    "                    ground_line = plt.plot(\n",
    "                        np.append(\n",
    "                            ground_truth_input_x_piccoor[i, -1], # np.append: 관찰된 궤적의 마지막 x 좌표와 실제 궤적의 모든 x 좌표를 하나의 배열로 결합\n",
    "                            ground_truth_output_x_piccoor[i, :],\n",
    "                        ),\n",
    "                        np.append(\n",
    "                            ground_truth_input_y_piccoor[i, -1],\n",
    "                            ground_truth_output_y_piccoor[i, :],\n",
    "                        ),\n",
    "                        color=\"#00FFFF\", # 형광 하늘색 // # \"b-\",\n",
    "                        linewidth=4,\n",
    "                        label=\"Ground Truth\",\n",
    "                        alpha=0.7,\n",
    "                    )[0]\n",
    "\n",
    "                    predict_line = plt.plot(\n",
    "                        np.append( # 관찰된 궤적의 마지막 x 좌표와 모델이 예측한 궤적의 모든 x 좌표를 하나의 배열로 결합\n",
    "                            ground_truth_input_x_piccoor[i, -1], # i번째 샘플의 관찰된 궤적의 마지막 x 좌표\n",
    "                            model_output_x_piccoor[i, :], # i번째 샘플의 모델이 예측한 궤적의 모든 x 좌표\n",
    "                        ),\n",
    "                        np.append( # 예측된 궤적이 관찰된 궤적의 끝에서 시작하는 연속적인 궤적으로 표시\n",
    "                            ground_truth_input_y_piccoor[i, -1],\n",
    "                            model_output_y_piccoor[i, :],\n",
    "                        ),\n",
    "                        color=\"#ADFF2F\", # 연두             // #\"#ffff00\", # 노랑\n",
    "                        ls=\"--\", # 선의 스타일을 점선으로 설정\n",
    "                        linewidth=4,\n",
    "                        label=\"Predicted Trajectory\",\n",
    "                        alpha=0.7,\n",
    "                    )[0]\n",
    "\n",
    "                plt.axis(\"off\")\n",
    "                plt.savefig(\n",
    "                    args.output_dir+\"/pic_{}.png\".format(pic_cnt),\n",
    "                    transparent=True # 투명으로 저장\n",
    "                )\n",
    "                plt.close()\n",
    "                pic_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    checkpoint = torch.load(args.restore_path) # .pt 파일을 불러올 경로\n",
    "    generator = get_generator(checkpoint)\n",
    "    # path = get_dset_path(args.dataset_name, args.dset_type)\n",
    "    dst_path = args.output_dir\n",
    "    if not os.path.exists(dst_path):\n",
    "        os.makedirs(dst_path)\n",
    "        print(f\"Directory {dst_path} created.\")\n",
    "    else:\n",
    "        print(f\"Directory {dst_path} already exists.\")\n",
    "    path = '/home/ngnadmin/dev/ngn_2024/MMT4/MMT/mmt/datasets/sdd_dC/test2'\n",
    "    _, loader = data_loader(args, path)\n",
    "    plot_trajectory(args, loader, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불러올 모델 체크포인트 파일 경로: /home/ngnadmin/dev/ngn_2024/MMT4/MMT/scripts_sdd/output/noscene/state0/obs8/1/lstm_0_with_model.pt\n",
      "이미지가 저장될 위치: /home/ngnadmin/dev/ngn_2024/MMT4/MMT/vis/sgan/fig/obs8/1\n",
      "축제거\n",
      "투명배경\n"
     ]
    }
   ],
   "source": [
    "# 주요 변수 확인\n",
    "print(f\"불러올 모델 체크포인트 파일 경로: {args.restore_path}\")\n",
    "print(f\"이미지가 저장될 위치: {args.output_dir}\")\n",
    "print(f\"축제거\")\n",
    "print(f\"투명배경\")\n",
    "# print(f\"모델 궤적만 가시화\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_736862/1730160679.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_736862/941808601.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# .pt 파일을 불러올 경로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# path = get_dset_path(args.dataset_name, args.dset_type)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdst_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmtp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmtp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmtp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmtp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         loaded_storages[key] = torch.storage.TypedStorage(\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m             dtype=dtype)\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmtp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmtp/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mps_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mmtp/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             )\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0muntyped_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0muntyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmtp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
